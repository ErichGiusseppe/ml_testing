{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c320046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4993f841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'carro': [1, [1]],\n",
       " 'compra': [1, [3]],\n",
       " 'industrial': [2, [3, 5]],\n",
       " 'libro': [2, [2, 5]],\n",
       " 'máquina': [3, [3, 4, 5]],\n",
       " 'mecánica': [1, [3]],\n",
       " 'nuevo': [2, [2, 5]],\n",
       " 'usado': [3, [1, 2, 4]],\n",
       " 'venta': [3, [1, 2, 4]]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def num_veces(search_string, string):\n",
    "    array_string = string.split(\" \")\n",
    "    cuenta = 0\n",
    "    for sub_string in array_string:\n",
    "        if sub_string == search_string:\n",
    "            cuenta += 1\n",
    "    return cuenta\n",
    "\n",
    "\n",
    "def array_palabras(corpus, vocabulario):\n",
    "    diccionario = {word: [0,[]] for word in vocabulario}\n",
    "    for id_documento in range(len(corpus)):\n",
    "        for word in vocabulario:\n",
    "            if num_veces(word, corpus[id_documento]) > 0:\n",
    "                diccionario[word][1].append(id_documento+1)\n",
    "            diccionario[word][0] = len(diccionario[word][1])\n",
    "    return diccionario\n",
    "\n",
    "def palabra_en_doc(corpus, palabra):\n",
    "    lista = np.zeros(len(corpus), dtype=int) \n",
    "    for id_documento in range(len(corpus)):\n",
    "        lista[id_documento] = num_veces(palabra, corpus[id_documento])\n",
    "    return lista\n",
    "\n",
    "terminos = [\n",
    "    \"carro\",\n",
    "    \"compra\",\n",
    "    \"industrial\",\n",
    "    \"libro\",\n",
    "    \"máquina\",\n",
    "    \"mecánica\",\n",
    "    \"nuevo\",\n",
    "    \"usado\",\n",
    "    \"venta\",\n",
    "]\n",
    "\n",
    "documentos = [\n",
    "    \"venta carro usado\",\n",
    "    \"venta libro usado venta libro nuevo\",\n",
    "    \"compra máquina industrial máquina mecánica\",\n",
    "    \"máquina venta usado\",\n",
    "    \"libro máquina industrial nuevo\"\n",
    "]\n",
    "\n",
    "array_palabras(documentos, terminos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d49c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((1, len([1,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd9e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae25cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carro [1 0 0 0 0]\n",
      "compra [0 0 1 0 0]\n",
      "industrial [0 0 1 0 1]\n",
      "libro [0 2 0 0 1]\n",
      "máquina [0 0 2 1 1]\n",
      "mecánica [0 0 1 0 0]\n",
      "nuevo [0 1 0 0 1]\n",
      "usado [1 1 0 1 0]\n",
      "venta [1 2 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "#def tf():\n",
    "for word in terminos:\n",
    "    print(word, palabra_en_doc(documentos, word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a6d53ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_docs_word(palabra, documentos):\n",
    "    df = 0\n",
    "    for id_documento in range(len(documentos)):\n",
    "        if num_veces(palabra,documentos[id_documento]) > 0:\n",
    "            df += 1\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d9e6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_docs_word(terminos[2], documentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d15c2f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_palabras = np.zeros(len(documentos))\n",
    "lista_palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72225a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa69f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_row(documentos, palabra):\n",
    "    lista_palabras = np.zeros((len(documentos)))\n",
    "    N = len(documentos)\n",
    "    for id_documento in range(len(documentos)):\n",
    "        idf = (N / num_docs_word(palabra,documentos))\n",
    "        tf = num_veces(palabra,documentos[id_documento])\n",
    "        lista_palabras[id_documento] =  tf * idf\n",
    "        \n",
    "    return lista_palabras\n",
    "tf_idf = np.zeros((len(terminos), len(documentos)))\n",
    "for id_word in range(len(terminos)):\n",
    "    tf_idf[id_word] = tf_idf_row(documentos, terminos[id_word])\n",
    "    #print(tf_idf)\n",
    "    #print(\"-----------------------\")\n",
    "    #idf = np.log10(1 + palab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0caf277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 5.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 2.5       , 0.        , 2.5       ],\n",
       "       [0.        , 5.        , 0.        , 0.        , 2.5       ],\n",
       "       [0.        , 0.        , 3.33333333, 1.66666667, 1.66666667],\n",
       "       [0.        , 0.        , 5.        , 0.        , 0.        ],\n",
       "       [0.        , 2.5       , 0.        , 0.        , 2.5       ],\n",
       "       [1.66666667, 1.66666667, 0.        , 1.66666667, 0.        ],\n",
       "       [1.66666667, 3.33333333, 0.        , 1.66666667, 0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79777518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad6a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tf_idf).to_csv(\"tf_idf_numeros.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21c15281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_row(documentos, palabra):\n",
    "    N = len(documentos)\n",
    "    df = num_docs_word(palabra, documentos)\n",
    "    idf = np.log10(N / df) if df > 0 else 0\n",
    "\n",
    "    lista_palabras = np.zeros(len(documentos))\n",
    "    for i, doc in enumerate(documentos):\n",
    "        tf = np.log10(1+ num_veces(palabra, doc))\n",
    "        lista_palabras[i] = tf * idf\n",
    "\n",
    "    return lista_palabras\n",
    "\n",
    "tf_idf = np.zeros((len(terminos), len(documentos)))\n",
    "for id_word, termino in enumerate(terminos):\n",
    "    tf_idf[id_word] = tf_idf_row(documentos, termino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ffcf3a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_query_col(documento_query, documentos, palabras):\n",
    "    N = len(documentos)\n",
    "    \n",
    "\n",
    "    lista_docs = np.zeros(len(palabras))\n",
    "    for i, palabra in enumerate(palabras):\n",
    "        tf = np.log10(1+num_veces(palabra, documento_query))\n",
    "        df = num_docs_word(palabra, documentos)\n",
    "        idf = np.log10(N / df) if df > 0 else 0\n",
    "        lista_docs[i] = tf * idf\n",
    "\n",
    "    return lista_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1513f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_query = np.zeros((len(terminos), 1))\n",
    "new_doc = \"compra máquina helado\"\n",
    "tf_idf_query  = tf_idf_query_col(new_doc, documentos, terminos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2018e568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.21041094, 0.        , 0.        , 0.06678313,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2195208",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = np.zeros((len(terminos), len(documentos)))\n",
    "for id_word, termino in enumerate(terminos):\n",
    "    tf_idf[id_word] = tf_idf_row(documentos, termino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7eef82dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21041094, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.21041094, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.11979188, 0.        , 0.11979188],\n",
       "       [0.        , 0.18986564, 0.        , 0.        , 0.11979188],\n",
       "       [0.        , 0.        , 0.10584875, 0.06678313, 0.06678313],\n",
       "       [0.        , 0.        , 0.21041094, 0.        , 0.        ],\n",
       "       [0.        , 0.11979188, 0.        , 0.        , 0.11979188],\n",
       "       [0.06678313, 0.06678313, 0.        , 0.06678313, 0.        ],\n",
       "       [0.06678313, 0.10584875, 0.        , 0.06678313, 0.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6973a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_docs = tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29929343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21041094, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.21041094, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.11979188, 0.        , 0.11979188],\n",
       "       [0.        , 0.18986564, 0.        , 0.        , 0.11979188],\n",
       "       [0.        , 0.        , 0.10584875, 0.06678313, 0.06678313],\n",
       "       [0.        , 0.        , 0.21041094, 0.        , 0.        ],\n",
       "       [0.        , 0.11979188, 0.        , 0.        , 0.11979188],\n",
       "       [0.06678313, 0.06678313, 0.        , 0.06678313, 0.        ],\n",
       "       [0.06678313, 0.10584875, 0.        , 0.06678313, 0.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c818fa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.21041094, 0.        , 0.        , 0.06678313,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ddcbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.68852156 0.17466089 0.09268924]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "query_vec = tf_idf_query.flatten()\n",
    "\n",
    "similaridades = []\n",
    "for col in tf_idf_docs.T:  \n",
    "    sim = np.dot(query_vec, col) / (norm(query_vec) * norm(col))\n",
    "    similaridades.append(sim)\n",
    "\n",
    "similaridades = np.array(similaridades)\n",
    "\n",
    "print(similaridades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8d5eca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.21041094, 0.        , 0.        , 0.06678313,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "406d87b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documentos ordenados: [2 4 3 1 0]\n",
      "Scores  [0.31625969 0.06678313 0.06678313 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "mask = tf_idf_query.flatten() > 0\n",
    "\n",
    "scores = []\n",
    "for col in tf_idf_docs.T:  \n",
    "    score = np.sum(col[mask])  \n",
    "    scores.append(score)\n",
    "\n",
    "scores = np.array(scores)\n",
    "\n",
    "top5_idx = np.argsort(scores)[::-1][:5]\n",
    "top5_scores = scores[top5_idx]\n",
    "\n",
    "print(\"documentos ordenados:\", top5_idx)\n",
    "print(\"Scores \", top5_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
